{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+1Pp0XcbL5J1ylCpsX8U/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["https://github.com/patrickloeber/pytorchTutorial/blob/master/05_1_gradientdescent_manually.py\n","\n","https://www.youtube.com/watch?v=E-I2DNVzQLg&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=5"],"metadata":{"id":"iisRET54eAcX"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aaBBp8B9d-YR","executionInfo":{"status":"ok","timestamp":1714841408740,"user_tz":-120,"elapsed":244,"user":{"displayName":"Nasreen Ahmed","userId":"04649825647281041989"}},"outputId":"f9b02163-d9fb-4912-d851-5a4a10884ee8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction before training : f(5) = 0.000\n","epoch 1: w = 1.200, loss =30.00000000\n","epoch 3: w = 1.872, loss =0.76800019\n","epoch 5: w = 1.980, loss =0.01966083\n","epoch 7: w = 1.997, loss =0.00050331\n","epoch 9: w = 1.999, loss =0.00001288\n","epoch 11: w = 2.000, loss =0.00000033\n","epoch 13: w = 2.000, loss =0.00000001\n","epoch 15: w = 2.000, loss =0.00000000\n","epoch 17: w = 2.000, loss =0.00000000\n","epoch 19: w = 2.000, loss =0.00000000\n","Prediction after the training f(5) = 10.000\n"]}],"source":["import numpy as np\n","\n","# compute every step manually\n","\n","# Linear regression\n","# f = w * x\n","\n","#here : f = 2 * x\n","\n","X = np.array([1,2,3,4],dtype = np.float32)\n","Y = np.array([2,4,6,8],dtype = np.float32)\n","\n","w = 0.0\n","\n","# model output\n","\n","def forward(x):\n","\n","  return w * x\n","\n","# loss : MSE\n","def loss(y,y_pred):\n","  return (( y_pred - y)**2).mean()\n","\n","# J = MSE = 1/N * ( w * x - y)**2\n","# dJ/dw = 1/N * 2*x (w * x - y)\n","\n","def gradient(x,y,y_pred):\n","  return np.mean(np.dot(2*x,y_pred-y))\n","\n","print(f'Prediction before training : f(5) = {forward(5):.3f}')\n","\n","# ----------------------Training -----------------------------\n","\n","learning_rate = 0.01\n","n_iters = 20\n","\n","for epoch in range(n_iters):\n","\n","  # predict = forward pass\n","  y_pred = forward(X)\n","\n","  #loss\n","  l = loss(Y,y_pred)\n","\n","  #calculate gradients\n","  dw = gradient(X,Y,y_pred)\n","\n","  #update weights\n","  w -= learning_rate * dw\n","\n","  if epoch %2 == 0:\n","\n","    print(f'epoch {epoch + 1}: w = {w:.3f}, loss ={l:.8f}')\n","\n","print(f'Prediction after the training f(5) = {forward(5):.3f}')"]}]}