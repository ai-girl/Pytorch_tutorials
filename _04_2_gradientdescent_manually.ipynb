{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPorAmRXIkGKkI6UNE1MfXH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["https://www.youtube.com/watch?v=E-I2DNVzQLg&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=5\n","\n","https://github.com/patrickloeber/pytorchTutorial/blob/master/05_2_gradientdescent_auto.py"],"metadata":{"id":"i_JG7evWlode"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRgh6uNflnov","executionInfo":{"status":"ok","timestamp":1714843000465,"user_tz":-120,"elapsed":269,"user":{"displayName":"Nasreen Ahmed","userId":"04649825647281041989"}},"outputId":"e2a88d89-d7aa-4817-9b35-8ca44318752a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction before training : f(5) = 0.000\n","epoch 1: w = 0.300, loss =30.00000000\n","epoch 11: w = 1.665, loss =1.16278565\n","epoch 21: w = 1.934, loss =0.04506890\n","epoch 31: w = 1.987, loss =0.00174685\n","epoch 41: w = 1.997, loss =0.00006770\n","epoch 51: w = 1.999, loss =0.00000262\n","epoch 61: w = 2.000, loss =0.00000010\n","epoch 71: w = 2.000, loss =0.00000000\n","epoch 81: w = 2.000, loss =0.00000000\n","epoch 91: w = 2.000, loss =0.00000000\n","Prediction after the training f(5) = 10.000\n"]}],"source":["import torch\n","\n","# compute every step manually\n","\n","# Linear regression\n","# f = w * x\n","\n","#here : f = 2 * x\n","\n","X = torch.tensor([1,2,3,4],dtype = torch.float32)\n","Y = torch.tensor([2,4,6,8],dtype = torch.float32)\n","\n","w = torch.tensor(0.0,dtype=torch.float32, requires_grad=True)\n","\n","# model output\n","def forward(x):\n","  return w * x\n","\n","# loss : MSE\n","def loss(y,y_pred):\n","  return (( y_pred - y)**2).mean()\n","\n","# J = MSE = 1/N * ( w * x - y)**2\n","# dJ/dw = 1/N * 2*x (w * x - y)\n","\n","#def gradient(x,y,y_pred):\n","#  return np.mean(np.dot(2*x,y_pred-y))\n","\n","\n","print(f'Prediction before training : f(5) = {forward(5):.3f}')\n","\n","# ----------------------Training -----------------------------\n","\n","learning_rate = 0.01\n","n_iters = 100\n","\n","for epoch in range(n_iters):\n","\n","  # predict = forward pass\n","  y_pred = forward(X)\n","\n","  #loss\n","  l = loss(Y,y_pred)\n","\n","  #calculate gradients\n","  #dw = gradient(X,Y,y_pred)\n","  # calculate gradients = backward pass\n","  l.backward()\n","\n","  #update weights\n","  with torch.no_grad():\n","    w -= learning_rate * w.grad\n","\n","  # zero the gradients after updating\n","\n","  w.grad.zero_()\n","\n","  if epoch %10 == 0:\n","\n","    print(f'epoch {epoch + 1}: w = {w:.3f}, loss ={l:.8f}')\n","\n","print(f'Prediction after the training f(5) = {forward(5):.3f}')"]}]}